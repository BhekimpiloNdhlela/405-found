{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "author: me bitch\n",
    "\n",
    "## Notebook to test various NLTK functions. ## \n",
    "\n",
    "General procedure for test data:\n",
    "- Break words into tokens\n",
    "- Strip tokens of punctuation\n",
    "- Remove commonly used words that do not provide meaningful content\n",
    "\n",
    "Test data with be tested against trained data. I'll be using data from the *NLTK corpus* to train the classifier. Testing **Naive Bayes Classifier** first. \n",
    "\n",
    "Currently looking into sentiment analysis (check bottom) to test whether a tweet is positive or negative.\n",
    "The project spec gives an example of topic modeling. Which utilises **LDA** to classify the features (topics) of tweets. You can then generate, for instance, a list of top ten tweet topics or how certain topics are related. \n",
    "\n",
    "The latter example is fairly simple compared to the former one. So will probably try to implement a version of the latter as soon as possible.\n",
    "\n",
    "Most of the classifier stuff we did in machine learning, I just need to figure out the structure of the data (tweets) and with what trained data am I going to compare with.\n",
    "\n",
    "Also, I'm using Jupyter notebook for quick testing purposes. \n",
    "\n",
    "**tl;dr**\n",
    "* Get the topic of a tweet and how it relates to other topics.\n",
    "* Sentiment analysis: Is a tweet negative or positive in nature.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Disclaimer:</b>You'll probably need to download a bunch of data libraries to run this notebook. Not needed at this moment. This is just testing data. I'm just uploading this to show my work in progress and to get some feedback. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import names\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "import pickle\n",
    "\n",
    "# will probably use these later for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tabs', 'selected', 'see', 'tweets', 'number', 'retweets', 'username', 'person', 'retweet', 'likes', 'indicated', 'ordered', 'recent', 'oldest', 'list', 'people', 'following', 'list', 'people', 'following']\n",
      "tab\n",
      "select\n",
      "see\n",
      "tweet\n",
      "number\n",
      "retweet\n",
      "usernam\n",
      "person\n",
      "retweet\n",
      "like\n",
      "indic\n",
      "order\n",
      "recent\n",
      "oldest\n",
      "list\n",
      "peopl\n",
      "follow\n",
      "list\n",
      "peopl\n",
      "follow\n"
     ]
    }
   ],
   "source": [
    "text = \"Tabs that can be selected to see all your tweets, with number of retweets (by username of person that did the retweet) and likes indicated, ordered from most recent to oldest, a list of people you\tare\tfollowing, and a list of people who are following you.\"\n",
    "\n",
    "# splits the text into token words\n",
    "stop_words = stopwords.words('english')\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# removes punctuation an dcommon words that don't contribute towards the text\n",
    "without_punctuation = []\n",
    "without_stop_words = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in punctuation:\n",
    "        without_punctuation.append(w)\n",
    "        \n",
    "for w in without_punctuation:\n",
    "    if w not in stop_words:\n",
    "        without_stop_words.append(w)        \n",
    "\n",
    "print(without_stop_words)\n",
    "\n",
    "# reduces words to its stem (root word)\n",
    "ps = PorterStemmer()\n",
    "for w in without_stop_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing getting parts of speech of each token. Not important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels each word with its parts of speech\n",
    "train_text = names.raw(\"female.txt\")\n",
    "sample_text = names.raw(\"male.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a rough implementation of sentiment analysis using **Naive Bayes Classifier**.  Still early phase. Using movie reviews data from NLTK as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Naive Bayes Algo accuracy percent:', 72.0)\n",
      "Most Informative Features\n",
      "               insulting = True              neg : pos    =     10.6 : 1.0\n",
      "              unoriginal = True              neg : pos    =      9.6 : 1.0\n",
      "                    sans = True              neg : pos    =      9.0 : 1.0\n",
      "            refreshingly = True              pos : neg    =      7.7 : 1.0\n",
      "              mediocrity = True              neg : pos    =      7.6 : 1.0\n",
      "                   tripe = True              neg : pos    =      7.6 : 1.0\n",
      "               dismissed = True              pos : neg    =      7.0 : 1.0\n",
      "             bruckheimer = True              neg : pos    =      6.3 : 1.0\n",
      "                  doubts = True              pos : neg    =      5.8 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.8 : 1.0\n",
      "                  stinks = True              neg : pos    =      5.8 : 1.0\n",
      "                    wits = True              pos : neg    =      5.7 : 1.0\n",
      "                    lang = True              pos : neg    =      5.7 : 1.0\n",
      "                  fabric = True              pos : neg    =      5.7 : 1.0\n",
      "                 topping = True              pos : neg    =      5.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category) \n",
    "             for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "    \n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "        \n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
